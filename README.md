# ðŸ§  pdfRAG â€“ Ask Questions from Your PDFs with LLMs

**pdfRAG** is a Retrieval-Augmented Generation (RAG) pipeline that lets you ask natural language questions from your PDF documents. It uses local LLMs (like LLaMA 2 via Ollama), vector databases (FAISS, ChromaDB, Qdrant), and semantic embeddings (DocArray) to give you grounded, contextual responses.

---

## ðŸš€ Features

- ðŸ“„ Ingest and process multiple PDFs
- ðŸ”Ž Chunk and embed text using **DocArray**
- ðŸ’¾ Store vectors in **ChromaDB**, **FAISS**, or **Qdrant**
- ðŸ§  Query with **LLaMA 2** via **Ollama**
- ðŸ”— Built using **LangChain** modules
- ðŸ’¬ Get answers based on the actual content inside your PDFs

---

## ðŸ§± Tech Stack

- **LangChain**
- **Ollama (LLaMA 2)**
- **ChromaDB / FAISS / Qdrant**
- **DocArray**
- **PyPDF**
- `os`, `itemgetter` (Python built-ins)
